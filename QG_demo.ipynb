{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing necessary Python libraries and downloading the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enables matplotlib plotting\n",
    "%matplotlib inline\n",
    "\n",
    "#Packages required for easy handling of data in python\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import wget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset. 10K events, 100 MB, no progressbar, so might need some patience.\n",
    "wget.download('https://cernbox.cern.ch/index.php/s/7SPmV3ShdaQkG5C/download')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying quark and gluon jets using a deep neural network\n",
    "\n",
    "The task of correctly identifying whether jet originated from a gluon or quark is important for almost any analysis of proton-proton collisions. This information is used to identify collision events that might contain interesting new physics and also correcting for detector effects in measured energies of jets.\n",
    "\n",
    "As jets are objects created due to a color charge carrying particle hadronizing into a host of particles color neutral particles. This is a manifestation of the color confinement of the Strong interaction. Even though determining the particle that originated the jet is not directly visible from the end state particles, it can be inferred from the properties of the jet. Whether the initial particle was a gluon or quark affects the measurable distributions of the particles within the jet.\n",
    "\n",
    "Let us begin by loading a sample of simulated quark and gluon jets, and inspecting its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data into a pandas DataFrame. This may also take a moment.\n",
    "\n",
    "data = pd.read_csv(\"small_10K.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we select a set of variables that are known to contain useful information, which can be used to separate quarks and gluons. All of these are mostly resulting from gluons being twice as likely to split into two compared to quarks. These variables are:\n",
    "\n",
    "__Jet multiplicity__. The number of charged particles in the jet. One would expect there to be on average more particles in a gluon jet than a quark jet.\n",
    "\n",
    "__Jet energy sharing variable__, $p_\\text{T}D$. Describes how evenly the energy is split between the particles inside the jet. Quark jets tend to have the energy centered mostly to a few particles, whereas gluon jets have their energy more evenly spread to all the constituent particles.\n",
    "\n",
    "__Jet minor axis__, $\\sigma_{2}$. Describes the shape of the jet. The gluon jets are wider on average compared to quark jets.\n",
    "\n",
    "Separating the relevant features from our dataframe and forming a binary target that is 1 if the jet is from a gluon and 0 if its from a quark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the interesting features\n",
    "df_=data[['QG_mult','QG_ptD','QG_axis2']].copy()\n",
    "\n",
    "#Adding a column containing the target\n",
    "df_['target']=data['isPhysG']\n",
    "\n",
    "#we have some data quality issue here: NaNs are nasty, so clean them away\n",
    "print(df_[df_['QG_ptD'].isnull()])\n",
    "df_.isna().sum()\n",
    "df_=df_.dropna()\n",
    "df_.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its always a good idea to inspect the distributions before starting to put too much effort into the machine learning task, just to see if there is something obvious visible in the data. Let us plot the variables to histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "columns=['QG_mult','QG_ptD','QG_axis2']\n",
    "binnings=[np.arange(0.0,36.0,1.0),np.arange(0.0,1.0,0.1),np.arange(0.0,0.2,0.01)]\n",
    "ind=0\n",
    "fig,axes = plt.subplots(1,3,figsize=(20,10))\n",
    "for column in columns:\n",
    "    #print ind, binnings[ind]\n",
    "    axes[ind].hist(df_[df_['target']==1][column],bins=binnings[ind],alpha=0.8,label='Gluon',density=1)\n",
    "    axes[ind].hist(df_[df_['target']==0][column],bins=binnings[ind],alpha=0.8,label='Quark',density=1)\n",
    "    axes[ind].set_xlabel(column)\n",
    "    axes[ind].legend()\n",
    "    ind=ind+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly there are some differences. For example chosing jets with more than 20 charged particles and minor axis value larger than 0.1 would contain mostly gluon jets. However we can do better by using a machine learning algorithm to learn these decision rules for us.\n",
    "\n",
    "# Keras - Tool for Deep Learning\n",
    "\n",
    "Keras provides a very simple interface to very powerful deep learning libraries like TensorFlow by Google. In fact, it is now integrated as a part of the TensorFlow library. It is the framework of preference for many in the particle physics community. Next we'll demonstrate that with just a few lines of code, we can produce a neural network classifier that is able to separate quark and gluon jets quite well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing some functions from keras and initializing it\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "#Split the data into training and test sample so that we test on data we havent\n",
    "#used in training. We split target to a separate dataframe so we dont use it in\n",
    "#training\n",
    "train_x,test = train_test_split(df_,test_size=0.15,random_state=7)\n",
    "train_y = np.array(train_x.target)\n",
    "train_x = np.array(train_x.drop(['target'],axis=1))\n",
    "\n",
    "#Defining the network shape\n",
    "a_inp = Input(shape=(train_x.shape[1],))\n",
    "a = Dense(50,activation='relu')(a_inp)\n",
    "a = Dense(50,activation='relu')(a)\n",
    "a = Dense(50,activation='relu')(a)\n",
    "a_out = Dense(1,activation='sigmoid')(a)\n",
    "model = Model(inputs=a_inp,outputs=a_out)\n",
    "model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['acc'])\n",
    "\n",
    "#weight the training samples so that there is equal weight on gluon and quark jets\n",
    "#even if there are different amount of them\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(train_y),train_y[:])\n",
    "\n",
    "#Perform the training\n",
    "model.fit(train_x,train_y,epochs=10,batch_size=1024,class_weight=class_weights,\n",
    "         validation_split=0.1,shuffle=True,verbose=0, callbacks=[TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the trained model, we can predict the classes of jets based on the three input variables. Let as create predictions for the test set and see how much our predictions separate the quark and gluon jets from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:,'predictions']=model.predict(np.array(test[['QG_mult','QG_ptD','QG_axis2']].copy()))\n",
    "\n",
    "plt.clf()\n",
    "binning=np.arange(0.0,1.0,0.05)\n",
    "plt.hist(test[test['target']==1]['predictions'],bins=binning,alpha=0.8,label=\"Gluons\",density=1)\n",
    "plt.hist(test[test['target']==0]['predictions'],bins=binning,alpha=0.8,label=\"Quarks\",density=1)\n",
    "plt.legend()\n",
    "plt.xlabel('DNN output value')\n",
    "plt.title('DNN classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score,roc_curve,auc\n",
    "fpr,tpr, thresholds  = roc_curve(np.array(test['target']),np.array(test['predictions']))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(fpr,tpr,'b',label='Classifier AUC = %0.2f'% roc_auc)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.savefig('roc_curve.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new variable shows better separation between quark and gluon jets than any of the three variables on their own. However the strength of Deep neural networks is not in the use of this type of high level variables, but instead using very low level features and find a new representation of the data that optimizes the discrimination power. \n",
    "\n",
    "The dataset contains variables with prefixes Cpfcand and Npfcand. These are the particles that belong to the jet. We try adding this information and use a larger network to see if it can extract extra information from these low level features to discriminate between the quarks and gluons better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below only works if root-file read in directly (probably because of per-particle information not written/read properly in csv-files)\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "data_=data[['QG_mult','QG_ptD','QG_axis2']].copy()\n",
    "particles=['PF_pT', 'PF_dR', 'PF_fromAK5Jet']\n",
    "particles_=data[['PF_pT', 'PF_dR', 'PF_fromAK5Jet']].copy()\n",
    "#add some of the \"per-particle information\" to the data frame/training\n",
    "print particles_.head()\n",
    "\n",
    "#Adding a column containing the target\n",
    "data_['target']=data['isPhysG']\n",
    "\n",
    "n_particles = 20\n",
    "df2=pd.DataFrame()\n",
    "#Crazy compact flattening/unrolling the particle level variables stored as vectors in the jets\n",
    "for column in particles:\n",
    "    column_names = [column+'_'+str(x) for x in range(n_particles)]\n",
    "    df2=pd.concat([df2, pd.DataFrame(pd.DataFrame(pad_sequences(particles_[column].tolist(),\n",
    "                                                                maxlen=n_particles, padding='post', dtype='float64'),\n",
    "                                                  columns=column_names))], axis=1)\n",
    "\n",
    "print data_.head()\n",
    "data_=pd.concat([data_, df2], axis = 1)\n",
    "print data_.head()\n",
    "\n",
    "\n",
    "data_=data_.dropna()\n",
    "#same cleaning as above.\n",
    "# However, would want to do more: \n",
    "# - Only keep those events where PF_fromAK5Jet is true\n",
    "# and [maybe; at least for charged particles] fromPV >=2 \n",
    "# (charged hadron selection to suppress PU)\n",
    "\n",
    "train_x,test = train_test_split(data_,test_size=0.15,random_state=7)\n",
    "train_y = np.array(train_x.target)\n",
    "train_x = np.array(train_x.drop(['target'],axis=1))\n",
    "\n",
    "a_inp = Input(shape=(train_x.shape[1],))\n",
    "a = Dense(250,activation='relu')(a_inp)\n",
    "a = Dense(100,activation='relu')(a)\n",
    "a = Dense(50,activation='relu')(a)\n",
    "a_out = Dense(1,activation='sigmoid')(a)\n",
    "model = Model(inputs=a_inp,outputs=a_out)\n",
    "model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['acc'])\n",
    "\n",
    "model.fit(train_x,train_y,epochs=6,batch_size=1024,class_weight=class_weights,\n",
    "         validation_split=0.1,shuffle=True,verbose=0, callbacks=[TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:,'predictions']=model.predict(np.array(test.drop(['target'],axis=1).copy()))\n",
    "\n",
    "plt.clf()\n",
    "binning=np.arange(0.0,1.0,0.05)\n",
    "plt.hist(test[test['target']==1]['predictions'],bins=binning,alpha=0.8,label=\"Gluons\",density=1)\n",
    "plt.hist(test[test['target']==0]['predictions'],bins=binning,alpha=0.8,label=\"Quarks\",density=1)\n",
    "plt.legend()\n",
    "plt.xlabel('DNN output value')\n",
    "plt.title('DNN classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score,roc_curve,auc\n",
    "fpr_,tpr_, thresholds  = roc_curve(np.array(test['target']),np.array(test['predictions']))\n",
    "roc_auc_ = auc(fpr_, tpr_)\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(fpr,tpr,'b',label='Before AUC = %0.2f'% roc_auc)\n",
    "plt.plot(fpr_,tpr_,'r',label='After AUC = %0.2f'% roc_auc_)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.savefig('roc_curve.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding new variables may increase the accuracy of the classifier. For the 10K sample here, the training sample is rather small and the input hasn't been cleaned, completely, so we even see a deteriorated performance. In genera, the performance can be further enhanced with more training statistics, more complex networks, preprocessing input variables with PCA whitening, and adding more input variables. But for this exercise this is enough."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "state": {
    "08a6f31b9a8c4a029404f1aaf223f74a": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "0d1e8b990608488193406b09b99a5e92": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "20fb655374694404809ec4d213f8e7d6": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "2212de19566f4041b5ebe53a9fda84ec": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "599e0a034ef64d9fae2ae6ab96977ad4": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "5b0ff9987cb348ef8643374a849056ba": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "5efe7190f5b04d739ff952cf2568d5b9": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "6a1a2dcc5c104c1691cb6db155d0ff2d": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "a66855a84a6647e4973583b782e299eb": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "aaacce64a9ab457faaf6c877d9e4d016": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "b4fe8611ac364e2195a4192ff95554db": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "b89afc9a81fb41f7a6210b8f41d225c5": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "c0504b8d91a344d69adc3c8ad57409d4": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "d1b34b9722fd48dea752c72d5090baef": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "deeef71954134001853319ac11d27f96": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "fcdd1c99847343b89ac7e9ede4887567": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "fd877073ebbe4aaba1567d9b6631d03b": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "ff6d2301d4354a61bca3e452e0b7b871": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
